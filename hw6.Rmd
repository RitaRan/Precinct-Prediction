---
title: "Modeling Manhattan Precincts"
output: html_notebook
---
## Write-Up
We began this assignment by cleaning up the data in the merge.R file. Since the code was only using violations recorded with one version of the street names (street, avenue, blvd vs. st, ave, boulevard, etc.), we mutated various abbreviations and common misspellings to their correct counterparts, so as to increase the amount of data. The more points we had, the more accurately the precincts would be defined. We did the same thing with all numbered streets (1st avenue to 1 avenue) and directional designations (e to east, w to west, etc.), because only records with only the number and no suffix, and only records with the full east/west/north/south, were being included. We also corrected a few edge cases like Avenue of the Americas and Park Street South. This cleanup alone got our score to around 0.3.  
    
Another small tweak we made to try to improve accuracy was to increase the raster resolution and assign the number of rows and columns in a ratio that reflected the size/shape of Manhattan (600 columns and 834 rows). We are not sure how much this helped, if at all, because it was implemented simultaneously to other improvements.
  
Our next, and most important task, was to tackle Central Park/Precinct 22. We chose to generate the fake data using a rejection sampling method. We defined a rectangle around Central Park using the eastern, western, southern, and northern most points of the Park as the boundaries of the rectangle, and then sampled 60,000 points from this rectangle. Because the area of Central Park occupies 1/3 of the area of the rectangle we defined, and we also wanted to keep balanced the amount of points for each precinct, so we generated 60,000 points to make sure that Precinct 22 had at least roughly the same amount of data as the precinct with the fewest data. (We originally sampled 20,000 points, and the 0.182 score cited below was the result with 20,000 samples. Increasing to 60,000 lowered the score further). We chose to define a smaller space around Central Park because sampling from all of Manhattan would have required us to sample many, many more points in order to get the desired number of points that fell within Central Park. Then we defined a function (is22) to determine if a sampled point was in the boundaries of the Park. We did this by defining the edges of the Park in line equation form, and then saying to return TRUE if the point was above and below the necessary lines required to be in the Park. We made use of the is22 function to determine which points we sampled were in the rectangle and then discarded those points outside. Since the original combined data included a bunch of points in the Central Park area but classified as other precincts, we used is22 function to remove those points from our original combined data. After generating fake data and cleaning up the original combined data, we combined them into one data set and used it to train our model. Filling Precinct 22 with fake data had a massive improvement on the map and our score. Precinct 22 appeared as a clear rectangle that very closely matched the Central Park boundaries. Before this step there was no Precinct 22, and Precincts 19 and 20, to the east and west of the Park, respectively, appeared as though they covered Central Park and split it somewhere near the middle. Our score came down to about a 0.182.  
  
Colin's editing of the Manhattan boundaries, which got rid of Roosevelt Island and some piers in Brooklyn which were both being counted as Manhattan precincts, had a large impact, and further reduced our score to about a 0.15.

An unsolved obstacle: Randall's Island is still inaccurate, but since there is no data for it, we had trouble coming up with a way to fix it without a scheme like the Central Park fake data scheme, which Colin said wasn't allowed. 


## Setup

```{r message=TRUE}
library(raster) # load before dplyr to avoid select bs

library(dplyr)
library(ggplot2)
library(sf)

# New packages
library(nnet)
library(xgboost)

# Load data
load(file="precinct.Rdata")
ggplot(combined, aes(x=x,y=y,color=factor(precinct))) + geom_point()
```


## Get Manhattan Info

```{r}
library(raster)
load("/data/nyc_parking/manh_bound.Rdata")
extb = st_bbox(bound) %>% .[c("xmin","xmax","ymin","ymax")] %>% extent()
rb = raster(extb, ncol=600, nrow=834) # Increased raster resolution 
rb = rasterize(as(bound,"Spatial"),rb)

plot(rb,asp=0)
```

### Get prediction locations

```{r}
pred_cells = which(!is.na(rb[]))
pred_locs = xyFromCell(rb, pred_cells) %>% as.data.frame() %>% tbl_df()
plot(pred_locs, pch=16, cex=0.1)
```

## Model 4 - xgboost

```{r}
library(xgboost)
# generate fake data for Central Park
combined %<>% filter(precinct!=22)

# Make rectangle around Central Park from which to sample data
x_span = seq(-73.9814800, -73.949670, 0.0002288386)
y_span = seq(40.76474,40.80046,0.0002334587)

# Sample points from the rectangle
x = sample(x_span, 60000,replace = TRUE)
y = sample(y_span, 60000,replace = TRUE)

# Define a function to determine if a sampled point is within the Park boundaries
is22 = function(x){
 if ((x[2]<=1.36555*x[1]+141.794) &&
     (x[2]<=8.86415-0.431818*x[1]) &&
     (x[2]>=1.36134*x[1]+141.467) &&
     (x[2]>=9.66207-0.420455*x[1]))
   return(TRUE)
 else
   return(FALSE)
}

# Add all points that are in the Park (Precinct 22) to the data
in22 = cbind(x,y) %>% apply(1,is22)
central = cbind(precinct = rep(22,length(x)),x,y) %>% .[in22,] %>% as_data_frame
combined %<>% filter(!combined[,c("x","y")] %>% apply(1,is22))
combined = bind_rows(combined, central)
combined = combined[sample(1:nrow(combined),nrow(combined),replace = FALSE),]

precincts = factor(combined$precinct) %>% levels()
y = (factor(combined$precinct) %>% as.integer()) - 1L
x = combined %>% select(x,y) %>% as.matrix()

m = xgboost(data=x, label=y, nthead=4, nround=25, max_depth = 15,objective="multi:softmax", num_class=length(precincts))

pred_xg = predict(m, newdata=as.matrix(pred_locs))
pred_xg = precincts[pred_xg+1]

ggplot(cbind(pred_locs, pred=pred_xg), aes(x=x,y=y,color=factor(pred))) + geom_point()
```


## Rasters -> Polygons

```{r}
r_xg = rb
r_xg[pred_cells] = as.numeric(pred_xg)
plot(r_xg)
```


## Polygonize

```{r}
source("polygonizer.R")
p = polygonizer(r_xg)
p = st_transform(p, 4326)
plot(p)

st_write(p,"precincts.json", "data", driver="GeoJSON", quiet=TRUE)
```